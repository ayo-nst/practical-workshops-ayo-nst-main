{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Image2.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m----> 2\u001b[0m \u001b[43mImage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mImage2.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m600\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mheight\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m300\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/IPython/core/display.py:957\u001b[0m, in \u001b[0;36mImage.__init__\u001b[0;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata, alt)\u001b[0m\n\u001b[1;32m    955\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munconfined \u001b[38;5;241m=\u001b[39m unconfined\n\u001b[1;32m    956\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malt \u001b[38;5;241m=\u001b[39m alt\n\u001b[0;32m--> 957\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mImage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwidth\u001b[39m\u001b[38;5;124m'\u001b[39m, {}):\n\u001b[1;32m    961\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;241m=\u001b[39m metadata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwidth\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/IPython/core/display.py:327\u001b[0m, in \u001b[0;36mDisplayObject.__init__\u001b[0;34m(self, data, url, filename, metadata)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 327\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_data()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/IPython/core/display.py:992\u001b[0m, in \u001b[0;36mImage.reload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    990\u001b[0m \u001b[38;5;124;03m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[39;00m\n\u001b[1;32m    991\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed:\n\u001b[0;32m--> 992\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mImage\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    993\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretina:\n\u001b[1;32m    994\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retina_shape()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/IPython/core/display.py:353\u001b[0m, in \u001b[0;36mDisplayObject.reload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    352\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_flags \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 353\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_flags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    354\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;66;03m# Deferred import\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Image2.png'"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='Image2.png',width = \"600\",height = \"300\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Here, each node on the left represents an input feature, the connecting lines represent\n",
    "the learned coefficients, and the node on the right represents the output, which is a\n",
    "weighted sum of the inputs.\n",
    "\n",
    "2. This model has a lot more coefficients (also called weights) to learn: there is one\n",
    "between every input and every hidden unit (which make up the hidden layer), and\n",
    "one between every unit in the hidden layer and the output.\n",
    "\n",
    "3. Computing a series of weighted sums is mathematically the same as computing just\n",
    "one weighted sum, so to make this model truly more powerful than a linear model,\n",
    "we need one extra trick. After computing a weighted sum for each hidden unit, a\n",
    "nonlinear function is applied to the result—usually the rectifying nonlinearity (also\n",
    "known as rectified linear unit or relu) or the tangens hyperbolicus (tanh). The result of\n",
    "this function is then used in the weighted sum that computes the output, ŷ. The two\n",
    "functions are visualized in the following Figure. The relu cuts off values below zero, while tanh\n",
    "saturates to –1 for low input values and +1 for high input values. Either nonlinear\n",
    "function allows the neural network to learn much more complicated functions than a\n",
    "linear model could:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Image3.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m----> 2\u001b[0m \u001b[43mImage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mImage3.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m400\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mheight\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m300\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/IPython/core/display.py:957\u001b[0m, in \u001b[0;36mImage.__init__\u001b[0;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata, alt)\u001b[0m\n\u001b[1;32m    955\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munconfined \u001b[38;5;241m=\u001b[39m unconfined\n\u001b[1;32m    956\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malt \u001b[38;5;241m=\u001b[39m alt\n\u001b[0;32m--> 957\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mImage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwidth\u001b[39m\u001b[38;5;124m'\u001b[39m, {}):\n\u001b[1;32m    961\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;241m=\u001b[39m metadata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwidth\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/IPython/core/display.py:327\u001b[0m, in \u001b[0;36mDisplayObject.__init__\u001b[0;34m(self, data, url, filename, metadata)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 327\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_data()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/IPython/core/display.py:992\u001b[0m, in \u001b[0;36mImage.reload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    990\u001b[0m \u001b[38;5;124;03m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[39;00m\n\u001b[1;32m    991\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed:\n\u001b[0;32m--> 992\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mImage\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    993\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretina:\n\u001b[1;32m    994\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retina_shape()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/IPython/core/display.py:353\u001b[0m, in \u001b[0;36mDisplayObject.reload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    352\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_flags \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 353\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_flags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    354\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;66;03m# Deferred import\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Image3.png'"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='Image3.png',width = \"400\",height = \"300\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the small neural network pictured in the first figure, the full formula for computing ŷ in the case of regression would be (when using a tanh nonlinearity):   \n",
    "h[0] = tanh(w[0, 0] * x[0] + w[1, 0] * x[1] + w[2, 0] * x[2] + w[3, 0] * x[3] + b[0])   \n",
    "h[1] = tanh(w[0, 1] * x[0] + w[1, 1] * x[1] + w[2, 1] * x[2] + w[3, 1] * x[3] + b[1])   \n",
    "h[2] = tanh(w[0, 2] * x[0] + w[1, 2] * x[1] + w[2, 2] * x[2] + w[3, 2] * x[3] + b[2])   \n",
    "ŷ = v[0] * h[0] + v[1] * h[1] + v[2] * h[2] + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, **w** are the weights between the input **x** and the hidden layer **h**, and **v** are the\n",
    "weights between the hidden layer **h** and the output ŷ. The weights **v** and **w** are learned\n",
    "from data, **x** are the input features, ŷ is the computed output, and **h** are intermediate\n",
    "computations. An important parameter that needs to be set by the user is the number\n",
    "of nodes in the hidden layer. This can be as small as 10 for very small or simple datasets\n",
    "and as big as 10,000 for very complex data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having large neural networks made up of many of these layers of computation is\n",
    "what inspired the term “deep learning.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data used here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we use the data **Avila** from UCI: https://archive.ics.uci.edu/ml/datasets/Avila#. The Avila data set has been extracted from 800 images of the 'Avila Bible', an XII century giant Latin copy of the Bible. The prediction task consists in associating each pattern to a copyist. In this lab, the‘avila-tr.txt'data is used. For your convenience, I have pre-processed an 'CSV' file in the Github."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Set Information:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLASS DISTRIBUTION (training set)\n",
    "\n",
    "A: 4286 \n",
    "\n",
    "B: 5 \n",
    "\n",
    "C: 103 \n",
    "\n",
    "D: 352 \n",
    "\n",
    "E: 1095 \n",
    "\n",
    "F: 1961 \n",
    "\n",
    "G: 446 \n",
    "\n",
    "H: 519 \n",
    "\n",
    "I: 831 \n",
    "\n",
    "W: 44 \n",
    "\n",
    "X: 522 \n",
    "\n",
    "Y: 266"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attribute Information:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1: intercolumnar distance \n",
    "\n",
    "F2: upper margin \n",
    "\n",
    "F3: lower margin \n",
    "\n",
    "F4: exploitation \n",
    "\n",
    "F5: row number \n",
    "\n",
    "F6: modular ratio \n",
    "\n",
    "F7: interlinear spacing \n",
    "\n",
    "F8: weight \n",
    "\n",
    "F9: peak number \n",
    "\n",
    "F10: modular ratio/ interlinear spacing \n",
    "\n",
    "Class: A, B, C, D, E, F, G, H, I, W, X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relevant Papers:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C. DeÂ Stefano, M. Maniaci, F. Fontanella, A. ScottoÂ diÂ Freca, \n",
    "Reliable writer identification in medieval manuscripts through page layout features: The 'Avila' Bible case, Engineering Applications of Artificial Intelligence, Volume 72, 2018, pp. 99-110. \n",
    "\n",
    "C. De Stefano, F. Fontanella, M. Maniaci and A. Scotto di Freca, 'A Method for Scribe Distinction in Medieval Manuscripts Using Page Layout Features', Lecture Notes in Computer Science, G. Maino and G. Foresti (eds.), Springer-Verlag, vol. 6978, pp. 393-402."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size: (10430, 11)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>F10</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.266074</td>\n",
       "      <td>-0.165620</td>\n",
       "      <td>0.320980</td>\n",
       "      <td>0.483299</td>\n",
       "      <td>0.172340</td>\n",
       "      <td>0.273364</td>\n",
       "      <td>0.371178</td>\n",
       "      <td>0.929823</td>\n",
       "      <td>0.251173</td>\n",
       "      <td>0.159345</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.130292</td>\n",
       "      <td>0.870736</td>\n",
       "      <td>-3.210528</td>\n",
       "      <td>0.062493</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>1.436060</td>\n",
       "      <td>1.465940</td>\n",
       "      <td>0.636203</td>\n",
       "      <td>0.282354</td>\n",
       "      <td>0.515587</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.116585</td>\n",
       "      <td>0.069915</td>\n",
       "      <td>0.068476</td>\n",
       "      <td>-0.783147</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>0.439463</td>\n",
       "      <td>-0.081827</td>\n",
       "      <td>-0.888236</td>\n",
       "      <td>-0.123005</td>\n",
       "      <td>0.582939</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.031541</td>\n",
       "      <td>0.297600</td>\n",
       "      <td>-3.210528</td>\n",
       "      <td>-0.583590</td>\n",
       "      <td>-0.721442</td>\n",
       "      <td>-0.307984</td>\n",
       "      <td>0.710932</td>\n",
       "      <td>1.051693</td>\n",
       "      <td>0.594169</td>\n",
       "      <td>-0.533994</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.229043</td>\n",
       "      <td>0.807926</td>\n",
       "      <td>-0.052442</td>\n",
       "      <td>0.082634</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>0.148790</td>\n",
       "      <td>0.635431</td>\n",
       "      <td>0.051062</td>\n",
       "      <td>0.032902</td>\n",
       "      <td>-0.086652</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         F1        F2        F3        F4        F5        F6        F7  \\\n",
       "0  0.266074 -0.165620  0.320980  0.483299  0.172340  0.273364  0.371178   \n",
       "1  0.130292  0.870736 -3.210528  0.062493  0.261718  1.436060  1.465940   \n",
       "2 -0.116585  0.069915  0.068476 -0.783147  0.261718  0.439463 -0.081827   \n",
       "3  0.031541  0.297600 -3.210528 -0.583590 -0.721442 -0.307984  0.710932   \n",
       "4  0.229043  0.807926 -0.052442  0.082634  0.261718  0.148790  0.635431   \n",
       "\n",
       "         F8        F9       F10 Class  \n",
       "0  0.929823  0.251173  0.159345     A  \n",
       "1  0.636203  0.282354  0.515587     A  \n",
       "2 -0.888236 -0.123005  0.582939     A  \n",
       "3  1.051693  0.594169 -0.533994     A  \n",
       "4  0.051062  0.032902 -0.086652     F  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data and show the basic information\n",
    "data=pd.read_csv(\"avila-tr.csv\")\n",
    "print('Data size: (%.f, %.f)\\n' % data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study the Multi-layer Perceptron model and its parameters\n",
    "We will use the multi-layer percepton to understand the basic usage of artificial neural network models. Class [MLPClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier) implements a multi-layer perceptron (MLP) algorithm that trains using Backpropagation. MLPClassifier has many parameters to configure. The effects of some important parameters have been discussed in our lecture, e.g., activation functions, number of hidden layers, number of units in a hidden layer, gradient descent, regularization, etc. So, in this workshop we would like to empirically study these parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Basic usage of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7584 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Specify features and the target\n",
    "X = data.drop(['Class'], axis = 'columns')\n",
    "y = data['Class']\n",
    "\n",
    "# Split the dataset into training data and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42)\n",
    "\n",
    "# Training the MLPClassifier with the default parameters (random_state=42)\n",
    "clf = MLPClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Output the accuracy on training data and test data respectively\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: %.4f \\n' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(random_state=42)\n",
      "\n",
      "# of layers (including the input layer): 3\n",
      "\n",
      "MLP structure: 10 X 100 X 12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Explore the learned MLP model\n",
    "print(clf)\n",
    "print('\\n# of layers (including the input layer): %.f\\n' % clf.n_layers_)\n",
    "print('MLP structure: %.f X %.f X %.f\\n' % (X.shape[1], clf.get_params()['hidden_layer_sizes'][0], clf.n_outputs_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Use 10-fold cross validation to report a more robust testing performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "# Use 10-fold cross validation to validate the model\n",
    "clf = MLPClassifier(random_state=42)\n",
    "scores_mlp_default = cross_val_score(clf, X, y, cv=10, verbose=1)\n",
    "print('Accuracy range for Multi-layer Perceptron: [%.4f, %.4f]; mean: %.4f; std: %.4f\\n'\n",
    "      % (scores_mlp_default.min(), scores_mlp_default.max(), scores_mlp_default.mean(), scores_mlp_default.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Increase the number of hidden units\n",
    "Here, we draw a figure to report the testing accuray with differnt number of hidden units [10,20,30,40,50,60,70,80,90,100]. The parameter 'hidden_layer_sizes' accepts a list of numbers specifying the number of units in each hidden layer. We plot the relationship between the parameter and the accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each number of hidden units, we use 10-fold cross validation to report the testing accuracy.\n",
    "# N.B.: The execution time is relatively long. This is to let you experience the intenstive computaiton required by artificial neural network models.\n",
    "cv_scores = []\n",
    "cv_scores_std = []\n",
    "hidden_unit_numbers = [[10],[20],[30],[40],[50],[60],[70],[80],[90],[100]]\n",
    "for i in hidden_unit_numbers:\n",
    "    clf_mlp = MLPClassifier(hidden_layer_sizes=i, random_state=42)\n",
    "    scores = cross_val_score(clf_mlp, X, y, scoring='accuracy', cv=10, verbose=1)\n",
    "    cv_scores.append(scores.mean())\n",
    "    cv_scores_std.append(scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the relationship\n",
    "plt.errorbar(hidden_unit_numbers, cv_scores, yerr=cv_scores_std, marker='x', label='Accuracy')\n",
    "plt.xlabel('Size of hidden units')\n",
    "plt.ylim(0.5, 0.9)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It can be seen that the accuracy increases when the number of units in the hidden layer increases. The reason is the a model with a bigger number of hiden layer units has a higher complexity to capture the information in data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task1. Number of hidder layers\n",
    "Set the number of hidden layers as two, and each has 100 units. Please report the accuracy score and compare it with the single hidden layer case mentioend above. Note that the execution time for this task is relative long. To track the progress of the execution, you could set the verbose parameter in the cross_val_score method as 'verbose=1'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a MLP model with two hidden layers\n",
    "clf_mlp  = MLPClassifier(hidden_layer_sizes = [100,100], random_state = 42)\n",
    "\n",
    "scores_mlp_2layers = cross_val_score(clf_mlp,\n",
    "                                      X, \n",
    "                                      y, \n",
    "                                      scoring = \"accuracy\", \n",
    "                                      cv = 10,\n",
    "                                      verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_mlp_2layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_mlp_2layers.min()\n",
    "scores_mlp_2layers.max()\n",
    "scores_mlp_2layers.mean()\n",
    "scores_mlp_2layers.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_mlp_2layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_mlp_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_ind(scores_mlp_default , scores_mlp_2layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Choose solver for the learning process\n",
    "As discussed in our lecture, we can use gradient descent methods (standard gradient and stochastic gradient descent) to learn weights for the error minimization problem. Moreover, we can have other solvers for the optimization problem. Here, we draw a figure to report the accuray with differnt solvers. The parameter 'solver' can take values from ['lbfgs','sgd', 'adam']. 'sgd' represents stochastic gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different solvers\n",
    "cv_scores = []\n",
    "cv_scores_std = []\n",
    "solvers = ['lbfgs', 'sgd', 'adam']\n",
    "for i in solvers:\n",
    "    clf_mlp = MLPClassifier(solver=i, random_state=42)\n",
    "    scores = cross_val_score(clf_mlp, X, y, scoring='accuracy', cv=10)\n",
    "    cv_scores.append(scores.mean())\n",
    "    cv_scores_std.append(scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the relationship\n",
    "plt.bar(solvers, cv_scores, yerr=cv_scores_std, label='Accuracy')\n",
    "plt.xlabel('Solvers')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It can be seen that sgd doesn't perform as well as the other two solvers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task2. Activation functions\n",
    "It can be seen above that the default activation function is 'ReLU'. As we discussed in our lecture, we could have different types of activation functions. Please try the possible functions 'identity’, ‘logistic’, ‘tanh’, and ‘relu’ provided by the API. Draw a figure to report the accuray with differnt activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Try different activation functions\n",
    "cv_scores = []\n",
    "cv_scores_std = []\n",
    "\n",
    "#solvers = ['lbfgs', 'sgd', 'adam']\n",
    "functions = [\"identity\" ,\"logistic\", \"tanh\", \"relu\" ]\n",
    "\n",
    "for i in functions:\n",
    "    clf_mlp = MLPClassifier(functions = i, random_state=42)\n",
    "    \n",
    "    scores = cross_val_score(clf_mlp, X, y, scoring='accuracy', cv=10, verbose = 1)\n",
    "    cv_scores.append(scores.mean())\n",
    "    cv_scores_std.append(scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(functions,cv_scores, yerr = cv_scores_std)\n",
    "plt.xlabel(\"Activation function\")\n",
    "plt.ylabel(\"Accuracy\"),\n",
    "plt.ylim(0.5,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Use different values of alpha\n",
    "The parameter alpha is the L2 penalty (regularization term) to overcome the overfitting issue. It balance the error caused the data and that by the model structure (number of weights). \n",
    "Here, please draw a figure to report the accuray with differnt values of alpha [0.0001,0.001,0.01, 0.1,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different regulaization parameters\n",
    "cv_scores = []\n",
    "cv_scores_std = []\n",
    "alphas = [0.0001,0.001,0.01, 0.1,1]\n",
    "for i in alphas:\n",
    "    clf_mlp = MLPClassifier(alpha=i, random_state=42)\n",
    "    scores = cross_val_score(clf_mlp, X, y, scoring='accuracy', cv=10)\n",
    "    cv_scores.append(scores.mean())\n",
    "    cv_scores_std.append(scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the relationship\n",
    "plt.errorbar(alphas, cv_scores, yerr=cv_scores_std, marker='x', label='Accuracy')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylim([0.6, 0.85])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It can be seen that when alpha increases, the prediction accuracy drops, showing that the overfitting issue of the model on this dataset is not a big problem.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task3. Increase the number of iterations\n",
    "This is related to the early stopping technique we mentioned in the lecture. Please explore when is good enough to stop the iteration of weight updating. Please draw a figure to report the accuray with differnt number of iterations [200,400,600,800,1000]. The parameter 'max_iter' can specify this setting. Note that the execution time for this task is relative long. To track the progress of the execution, you could set the verbose parameter in the cross_val_score method as 'verbose=1'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different number of iterations. Plot the relationship between the performance and the number of iterations.\n",
    "cv_scores = []\n",
    "cv_scores_std = []\n",
    "\n",
    "#alphas = [0.0001,0.001,0.01, 0.1,1]\n",
    "iteration_numbers = [200,400,600,800,1000]\n",
    "\n",
    "for i in iteration_numbers:\n",
    "    clf_mlp = MLPClassifier(max_iter = i, random_state=42)\n",
    "    scores = cross_val_score(clf_mlp, X, y, scoring='accuracy', cv=10)\n",
    "    cv_scores.append(scores.mean())\n",
    "    cv_scores_std.append(scores.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing with other classification models\n",
    "### Task4. Compare the results with Naive Bayes (GaussianNB) and K-Nearest Neighbors (K=1)\n",
    "Compare their accuracy scores and use t test to show if their perofrmance has siginficantly different with significance level 0.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compare with the two models we used before\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf_gnb = GaussianNB()\n",
    "\n",
    "scores_gnb = cross_val_score(clf_gnb, X,y, cv= 10)\n",
    "\n",
    "scores_gnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_gnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy range for Gaussian Naive Bayes : [%.4f, %.4f], mean: [%.4f] , std:[%.4f]\" % \n",
    "     (scores_gnb.min(),\n",
    "      scores_gnb.max(),\n",
    "      scores_gnb.mean(),\n",
    "      scores_gnb.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf_knn = KNeighborsClassifier(n_neighbors = 1)\n",
    "\n",
    "scores_knn = cross_val_score(clf_knn , X, y, cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy range for KNN : [%.4f, %.4f], mean: [%.4f] , std:[%.4f]\" % \n",
    "     (scores_knn.min(),\n",
    "      scores_knn.max(),\n",
    "      scores_knn.mean(),\n",
    "      scores_knn.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_mlp = MLPClassifier(random_state = 42)\n",
    "scores_mlp = cross_val_score(clf_mlp, X, y, cv = 10, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy range for Multi-layer perceptron : [%.4f, %.4f], mean: [%.4f] , std:[%.4f]\" % \n",
    "     (scores_mlp.min(),\n",
    "      scores_mlp.max(),\n",
    "      scores_mlp.mean(),\n",
    "      scores_mlp.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_ind(scores_mlp , scores_knn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
